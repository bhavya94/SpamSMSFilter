{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bhavya Sharma &nbsp;&nbsp;&nbsp;&nbsp;                                               Carnegie Mellon University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following project is a classification task to classify SMS as spam or not spam. The data was taken from UC Irvine Machine Learning repository https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_df = pd.read_csv(\"spam.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have two major columns - 'v1' has binary values - ham (not spam) and spam. Text consists of the original SMS that was collected from various soruces. Unnamed columns are created due to overflow of text to next cell in CSV file. Lets begin by properly renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>ud1</th>\n",
       "      <th>ud2</th>\n",
       "      <th>ud3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  ud1  ud2  ud3\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  NaN  NaN  NaN\n",
       "1   ham                      Ok lar... Joking wif u oni...  NaN  NaN  NaN\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  NaN  NaN  NaN\n",
       "3   ham  U dun say so early hor... U c already then say...  NaN  NaN  NaN\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  NaN  NaN  NaN"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.columns = ['label','text','ud1','ud2','ud3']\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check if the columns ud1, ud2 and ud3 are all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud1 = list(spam_df.loc[:,'ud1'])\n",
    "len(set(ud1))\n",
    "\n",
    "#There are 44 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' But at d end my love compromised me for everything:-(\\\\\".. Gud mornin:-)\"',\n",
       " ' Dont Come Near My Body..!! Bcoz My Hands May Not Come 2 Wipe Ur Tears Off That Time..!Gud ni8\"',\n",
       " ' ENJOYIN INDIANS AT THE MO..yeP. SaLL gOoD HehE ;> hows bout u shexy? Pete Xx\\\\\"\"',\n",
       " ' GOD said',\n",
       " ' Gud night....\"',\n",
       " ' HAD A COOL NYTHO',\n",
       " ' HOPE UR OK... WILL GIVE U A BUZ WEDLUNCH. GO OUTSOMEWHERE 4 ADRINK IN TOWN..CUD GO 2WATERSHD 4 A BIT? PPL FROMWRK WILL BTHERE. LOVE PETEXXX.\\\\\"\"',\n",
       " ' HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE JEN XXX\\\\\"\"',\n",
       " \" I don't mind\",\n",
       " ' I\\'ll come up\"',\n",
       " ' PO Box 1146 MK45 2WT (2/3)\"',\n",
       " ' PO Box 5249',\n",
       " ' SHE SHUDVETOLD U. DID URGRAN KNOW?NEWAY',\n",
       " ' \\\\\"It is d wonderful fruit that a tree gives when it is being hurt by a stone.. Good night......\"',\n",
       " ' always give response 2 who cares 4 U\\\\\"... Gud night..swt dreams..take care\"',\n",
       " ' b\\'coz nobody will fight for u. Only u &amp; u have to fight for ur self &amp; win the battle. -VIVEKANAND- G 9t.. SD..\"',\n",
       " ' bt not his girlfrnd... G o o d n i g h t . . .@\"',\n",
       " ' but dont try to prove it..\\\\\" .Gud noon....\"',\n",
       " ' but dont try to prove\\\\\" ..... Gud mrng...\"',\n",
       " ' but watever u shared should be true\\\\\"....\"',\n",
       " ' don\\'t miss ur best life for anything... Gud nyt...\"',\n",
       " ' hopeSo hunny. i amnow feelin ill & ithink i may have tonsolitusaswell! damn iam layin in bedreal bored. lotsof luv me xxxx\\\\\"\"',\n",
       " ' its a miracle to Love a person who can\\'t Love anyone except U...\\\\\" Gud nyt...\"',\n",
       " ' just as a shop has to give a guarantee on what they sell. B. G.\"',\n",
       " ' justthought iåÕd sayhey! how u doin?nearly the endof me wk offdam nevamind!We will have 2Hook up sn if uwant m8? loveJen x.\\\\\"\"',\n",
       " ' like you are the KING\\\\\"...! OR \\\\\"Walk like you Dont care',\n",
       " ' smoke hella weed\\\\\"\"',\n",
       " ' that\\'s the tiny street where the parking lot is\"',\n",
       " ' the person is definitely special for u..... But if the person is so special',\n",
       " ' the toughest is acting Happy with all unspoken pain inside..\\\\\"\"',\n",
       " ' wanted to say hi. HI!!!\\\\\" Stop? Send STOP to 62468\"',\n",
       " ' we made you hold all the weed\\\\\"\"',\n",
       " '.;-):-D\"',\n",
       " 'DEVIOUSBITCH.ANYWAY',\n",
       " 'GN',\n",
       " 'JUST GOT PAYED2DAY & I HAVBEEN GIVEN Aå£50 PAY RISE 4MY WORK & HAVEBEEN MADE PRESCHOOLCO-ORDINATOR 2I AM FEELINGOOD LUV\\\\\"\"',\n",
       " 'JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIGNORE MYCALLS',\n",
       " 'PROBPOP IN & CU SATTHEN HUNNY 4BREKKIE! LOVE JEN XXX. PSXTRA LRG PORTIONS 4 ME PLEASE \\\\\"\"',\n",
       " \"Well there's still a bit left if you guys want to tonight\",\n",
       " '\\\\\" not \\\\\"what i need to do.\\\\\"\"',\n",
       " 'just been in bedbut mite go 2 thepub l8tr if uwana mt up?loads a luv Jenxxx.\\\\\"\"',\n",
       " nan,\n",
       " 'this wont even start........ Datz confidence..\"',\n",
       " 'u hav2hear it!c u sn xxxx\\\\\"\"'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ud1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ud2:11\n",
      "Unique values in ud3:6\n"
     ]
    }
   ],
   "source": [
    "ud2 = list(spam_df.loc[:,'ud2'])\n",
    "ud3 = list(spam_df.loc[:,'ud3'])\n",
    "print('Unique values in ud2:'+str(len(set(ud2))))\n",
    "print('Unique values in ud3:'+str(len(set(ud3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can merge all these columns with the original text column to have only 2 columns for our classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = spam_df.replace(np.nan, '', regex=True)\n",
    "spam_df['text'] = spam_df[['text', 'ud1','ud2','ud3']].apply(lambda x: ''.join(x), axis=1)\n",
    "spam_df = spam_df.drop(columns=['ud1','ud2','ud3'])\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets convert label column to 0 and 1, where 1 denotes spam and 0 denots ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = spam_df.assign(label = pd.Series(np.where(spam_df.label.values == 'spam', 1, 0),\n",
    "          spam_df.index))\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use nltk library for processing the text and perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bhavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bhavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bhavya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following function will lower the case, and handles the punctuations in the text of the dataframe followed by which it generates tokens for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(text, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i,\" \")\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for i in range (0,len(tokens)):\n",
    "        tokens[i] = lemmatizer.lemmatize(tokens[i])\n",
    "    return tokens\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n",
      "['okay', 'name', 'ur', 'price', 'a', 'long', 'a', 'it', 'legal', 'wen', 'can', 'i', 'pick', 'them', 'up', 'y', 'u', 'ave', 'x', 'am', 'xx']\n"
     ]
    }
   ],
   "source": [
    "# Lets test our function:\n",
    "print(process(spam_df.loc[0,'text']))\n",
    "print(process(spam_df.loc[100,'text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to process all the rows of text and adding them back into dataframe, we can create the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(df, lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    df1 = df.copy()\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    text = (df1.loc[:,'text'])\n",
    "    processed = []\n",
    "    for i in text:\n",
    "        processed.append(process(i))\n",
    "    df1 = df1.assign(text = processed)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  [go, until, jurong, point, crazy, available, o...\n",
      "1      0                     [ok, lar, joking, wif, u, oni]\n",
      "2      1  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
      "3      0  [u, dun, say, so, early, hor, u, c, already, t...\n",
      "4      0  [nah, i, dont, think, he, go, to, usf, he, lif...\n"
     ]
    }
   ],
   "source": [
    "processed_spam = process_all(spam_df)\n",
    "print(processed_spam.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to create a TF-IDF vector for our text. We also need to remove the rare words and stop words. For the purpose of this classification, it can be assumed that the words that appear only once are rare and do not add much information to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets begin with getting a list of rare words in our text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rare_words(processed_spam):\n",
    "    \n",
    "    text = list(processed_spam.loc[:,'text'])\n",
    "    check = [j for i in text for j in i] # create list of lists\n",
    "    counter = Counter(check)\n",
    "    a = []\n",
    "    for i in counter.elements():\n",
    "        if(counter[i]==1):\n",
    "            a.append(i)\n",
    "    return sorted(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4175\n"
     ]
    }
   ],
   "source": [
    "rare_words = get_rare_words(processed_spam)\n",
    "print(len(rare_words)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the purpose of classification, we will try Naives Bayes, Logisitic Regression, and Support Vector Machine (Linear Kernel) and select the the classifier which gives us the best metrics. We will also try our data on default model (classifies according to frequency of labels) to set a standard for our selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will also use k-fold cross-validation to ensure that our models do not overfit. The cross-validation function will call each classifer and generate a dataframe of 'predicted' and 'actual' responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create a confusion matrix for each classifer to assess its performance using the predicted and actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets begin with creating a function to generate a sparse matrix of features for each sms (excluding the rarewords and stop words) and a numpy array for the labels. The classifiers will train on the matrix and predict using the TF-IDF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(train, rare_words):\n",
    "    text = train.loc[:,'text']\n",
    "    text_string = []\n",
    "    for i in range(0, len(text)):\n",
    "        text_string.append(\" \".join(str(x) for x in text[i]))\n",
    "    tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "    stopwords=nltk.corpus.stopwords.words('english')\n",
    "    tfidf.stop_words = stopwords + rare_words\n",
    "    matrix = tfidf.fit_transform(text_string)\n",
    "    y = np.array(train.loc[:,'label'])\n",
    "    return(tfidf,matrix,y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Classifier functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def get_pred_logreg(train,test,rare_words):\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    (tfidf, X, y) = create_features(train, rare_words)\n",
    "    lm = LogisticRegression()\n",
    "    lm.fit(X,y)\n",
    "    \n",
    "    query = test.loc[:,'text']# get test input data\n",
    "    #transform the test data\n",
    "    query_string = []\n",
    "    for i in range(0, len(query)):\n",
    "        query_string.append(\" \".join(str(x) for x in query[i]))\n",
    "    query_matrix = tfidf.transform(query_string)\n",
    "    predicted_response = lm.predict(query_matrix)\n",
    "    \n",
    "    return pd.DataFrame({'Predicted':predicted_response, 'Actual':test.loc[:,'label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "def get_pred_svm(train,test,rare_words):\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    (tfidf, X, y) = create_features(train, rare_words)\n",
    "    svm_model = svm.SVC(kernel = 'linear')\n",
    "    svm_model.fit(X,y)\n",
    "    \n",
    "    query = test.loc[:,'text']# get test input data\n",
    "    #transform the test data\n",
    "    query_string = []\n",
    "    for i in range(0, len(query)):\n",
    "        query_string.append(\" \".join(str(x) for x in query[i]))\n",
    "    query_matrix = tfidf.transform(query_string)\n",
    "    predicted_response = svm_model.predict(query_matrix)\n",
    "    \n",
    "    return pd.DataFrame({'Predicted':predicted_response, 'Actual':test.loc[:,'label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "def get_pred_nb(train,test,rare_words):\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    (tfidf, X, y) = create_features(train, rare_words)\n",
    "    gnb = GaussianNB()\n",
    "    X = X.toarray()\n",
    "    gnb.fit(X,y)\n",
    "    \n",
    "    query = test.loc[:,'text']# get test input data\n",
    "    #transform the test data\n",
    "    query_string = []\n",
    "    for i in range(0, len(query)):\n",
    "        query_string.append(\" \".join(str(x) for x in query[i]))\n",
    "    query_matrix = tfidf.transform(query_string)\n",
    "    query_matrix = query_matrix.toarray()\n",
    "    predicted_response = gnb.predict(query_matrix)\n",
    "    \n",
    "    return pd.DataFrame({'Predicted':predicted_response, 'Actual':test.loc[:,'label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default Classifier\n",
    "def get_pred_default(train,test):\n",
    "    y = train.loc[:,'label']\n",
    "    \n",
    "    #Get the frequently occuring category in training data\n",
    "    arity_name, arity_freq = np.unique(y, return_counts = True)\n",
    "    for i in range(0,len(arity_freq)):\n",
    "        if(arity_freq[i] == max(arity_freq)):\n",
    "            pred_def = i\n",
    "    predicted_response = [pred_def]*len(test)\n",
    "    return pd.DataFrame({'Predicted':predicted_response, 'Actual':test.loc[:,'label']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The k-fold cross-validation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation function\n",
    "\n",
    "def do_cv_class(df, num_folds, model_name):\n",
    "    \n",
    "    # Randomize the dataframe\n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    #creation of  k folds\n",
    "    quotient = len(df)//num_folds\n",
    "    q_array = np.array([quotient])\n",
    "    \n",
    "    #create array of size k with quotient as elements\n",
    "    q_list = np.repeat(q_array, [num_folds], axis=0) \n",
    "    \n",
    "    #distribute the remainder amongst first few folds\n",
    "    remainder = len(df)%num_folds\n",
    "    for i in range (0,remainder):\n",
    "        q_list[i] = q_list[i]+1\n",
    "    \n",
    "    # create a list of starting indexes for the k-folds\n",
    "    k_index=[]\n",
    "    k_index.append(q_list[0]) \n",
    "    for i in range(1,len(q_list)):\n",
    "        k_index.append(q_list[i] + k_index[i-1])\n",
    "\n",
    "    # create test and train data for each fold and get the dataframe\n",
    "    final_df = pd.DataFrame()\n",
    "    for i in range(0,len(k_index)):\n",
    "        if(i == 0):\n",
    "            test = df.iloc[:k_index[i],:]\n",
    "            train = df.drop(df.index[:k_index[i]])\n",
    "            if (model_name == 'logreg'):\n",
    "                output_df = get_pred_logreg(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'svm'):\n",
    "                output_df = get_pred_svm(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'nb'):\n",
    "                output_df = get_pred_nb(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'default'):\n",
    "                output_df = get_pred_default(train,test)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            final_df = final_df.append(output_df)\n",
    "        else:\n",
    "            test = df.iloc[k_index[i-1]:k_index[i],:]\n",
    "            train = df.drop(df.index[k_index[i-1]:k_index[i]])\n",
    "            if (model_name == 'logreg'):\n",
    "                output_df = get_pred_logreg(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'svm'):\n",
    "                output_df = get_pred_svm(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'nb'):\n",
    "                output_df = get_pred_nb(train,test,rare_words)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            elif(model_name == 'default'):\n",
    "                output_df = get_pred_default(train,test)\n",
    "                fold_list = [i]*len(output_df)\n",
    "                output_df = output_df.assign(folds = fold_list)\n",
    "            final_df = final_df.append(output_df)\n",
    "\n",
    "    return final_df # k-size dataframe with predicted and actual values of k-folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to print confusion matrix and calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cont_table(pred, cutoff=0.5):\n",
    "\n",
    "    # converting pandas dataframe to list\n",
    "    # If using list comment below\n",
    "    pred_data = pred.iloc[:, 0:2].copy()\n",
    "    data_output = pd.np.array(pred_data)\n",
    "    # If using list comment above\n",
    "\n",
    "    predicted_output = [float(i[0]) for i in data_output] # first column of list are the Predicted values\n",
    "    actual_output = [int(i[1]) for i in data_output] # Second column of list are the Actual values\n",
    "    # returns list = [[FALSE, TRUE][IF CONDITION] FOR a row in LIST]\n",
    "    predicted_output_manipulate = [[0, 1][x > cutoff] for x in predicted_output] # can also be performed by map(lambda x: [0, 1][x > cutoff], predicted_output)\n",
    "\n",
    "    n11_TP = sum([[0, 1][predicted_output_manipulate[i] == 1 and actual_output[i] == 1] for i in range(len(predicted_output))])\n",
    "    n00_TN = sum([[0, 1][predicted_output_manipulate[i] == 0 and actual_output[i] == 0] for i in range(len(predicted_output))])\n",
    "    n10_FN = sum([[0, 1][predicted_output_manipulate[i] == 0 and actual_output[i] == 1] for i in range(len(predicted_output))])\n",
    "    n01_FP = sum([[0, 1][predicted_output_manipulate[i] == 1 and actual_output[i] == 0] for i in range(len(predicted_output))])\n",
    "    Pos = n11_TP + n10_FN\n",
    "    Neg = n01_FP + n00_TN\n",
    "    PPos = n11_TP + n01_FP\n",
    "    PNeg = n10_FN + n00_TN\n",
    "    print(\"           |  PPos \\t PNeg \\t | Sums\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"actual pos |  %d \\t %d \\t | %d\" % (n11_TP, n10_FN, Pos))\n",
    "    print(\"actual neg |  %d \\t %d \\t | %d\" % (n01_FP, n00_TN, Neg)) \n",
    "    print(\"-------------------------------------\") \n",
    "    print(\"Sums       |  %d \\t %d \\t | %d\" % (PPos, PNeg, (Pos+Neg))) \n",
    "    return None\n",
    "\n",
    "def get_metrics(pred, cutoff=0.5):\n",
    "    ### your implementation goes here\n",
    "    pred_data = pred.iloc[:, 0:2].copy()\n",
    "    data_output = pd.np.array(pred_data)\n",
    "    # If using list comment above\n",
    "\n",
    "    predicted_output = [float(i[0]) for i in data_output] # first column of list are the Predicted values\n",
    "    actual_output = [int(i[1]) for i in data_output] # Second column of list are the Actual values\n",
    "    # returns list = [[FALSE, TRUE][IF CONDITION] FOR a row in LIST]\n",
    "    predicted_output_manipulate = [[0, 1][x > cutoff] for x in predicted_output] # can also be performed by map(lambda x: [0, 1][x > cutoff], predicted_output)\n",
    "\n",
    "    n11_TP = sum([[0, 1][predicted_output_manipulate[i] == 1 and actual_output[i] == 1] for i in range(len(predicted_output))])\n",
    "    n00_TN = sum([[0, 1][predicted_output_manipulate[i] == 0 and actual_output[i] == 0] for i in range(len(predicted_output))])\n",
    "    n10_FN = sum([[0, 1][predicted_output_manipulate[i] == 0 and actual_output[i] == 1] for i in range(len(predicted_output))])\n",
    "    n01_FP = sum([[0, 1][predicted_output_manipulate[i] == 1 and actual_output[i] == 0] for i in range(len(predicted_output))])\n",
    "    Pos = n11_TP + n10_FN\n",
    "    Neg = n01_FP + n00_TN\n",
    "    PPos = n11_TP + n01_FP\n",
    "    PNeg = n10_FN + n00_TN\n",
    "    \n",
    "    if(Neg == 0):\n",
    "        Accuracy = float(n11_TP+n00_TN)/float(Pos+Neg)\n",
    "        Recall = float(n11_TP)/float(Pos)\n",
    "        Precision = float(n11_TP)/float(n11_TP+n01_FP)\n",
    "        TP_rate = float(n11_TP)/float(n11_TP+n10_FN)\n",
    "        FP_rate = 'N/A'\n",
    "    elif(Pos == 0):\n",
    "        TP_rate = 'N/A'\n",
    "        FP_rate = float(n01_FP)/float(n00_TN+n01_FP)\n",
    "        Accuracy = float(n11_TP+n00_TN)/float(Pos+Neg)\n",
    "        Precision = float(n11_TP)/float(n11_TP+n01_FP)\n",
    "        Recall = 'N/A'\n",
    "    else:\n",
    "        TP_rate = float(n11_TP)/float(n11_TP+n10_FN)\n",
    "        FP_rate = float(n01_FP)/float(n00_TN+n01_FP)\n",
    "        Accuracy = float(n11_TP+n00_TN)/float(Pos+Neg)\n",
    "        Precision = float(n11_TP)/float(n11_TP+n01_FP)\n",
    "        Recall = float(n11_TP)/float(Pos)\n",
    "\n",
    "    return pd.DataFrame({'True Positive Rate':TP_rate, 'False Positive Rate':FP_rate, 'Accuracy':Accuracy, 'Precision':Precision, 'Recall':Recall}, index = [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models using Cross-validation (k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  0 \t 0 \t | 0\n",
      "actual neg |  747 \t 4825 \t | 5572\n",
      "-------------------------------------\n",
      "Sums       |  747 \t 4825 \t | 5572\n",
      "   Accuracy  False Positive Rate  Precision Recall True Positive Rate\n",
      "0  0.865937             0.134063        0.0    N/A                N/A\n"
     ]
    }
   ],
   "source": [
    "#DEFAULT/BASE MODEL\n",
    "tmp = do_cv_class(processed_spam,10,'default') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the number of not-spam labels are significantly higher than spam labels in our data, the accuracy of the base model is 86%. Hence, on classifying all SMS as not-spam, we will still be 86% accurate about our classification. Thus, our chosen model needs be highly accurate to beat the base model AND it must have lower false-positive rate to prevent not-spams from getting classified as spam messages. (Assuming the cost of getting not-spams is higher than preventing spams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  574 \t 10 \t | 584\n",
      "actual neg |  173 \t 4815 \t | 4988\n",
      "-------------------------------------\n",
      "Sums       |  747 \t 4825 \t | 5572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.967157             0.034683   0.768407  0.982877            0.982877\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "tmp = do_cv_class(processed_spam,10,'logreg') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  662 \t 554 \t | 1216\n",
      "actual neg |  85 \t 4271 \t | 4356\n",
      "-------------------------------------\n",
      "Sums       |  747 \t 4825 \t | 5572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.885319             0.019513   0.886212  0.544408            0.544408\n"
     ]
    }
   ],
   "source": [
    "#NAIVES BAYES\n",
    "tmp = do_cv_class(processed_spam,10,'nb') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  674 \t 7 \t | 681\n",
      "actual neg |  73 \t 4818 \t | 4891\n",
      "-------------------------------------\n",
      "Sums       |  747 \t 4825 \t | 5572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.985642             0.014925   0.902276  0.989721            0.989721\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "tmp = do_cv_class(processed_spam,10,'svm') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM gives us the highest accuracy and lowest false-positive rate and hence is the model of our choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on a validation set (taken out from the original dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>0</td>\n",
       "      <td>[mum, not, going, robinson, already]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0</td>\n",
       "      <td>[wat, make, some, people, dearer, is, not, jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>[ha, ha, ha, good, joke, girl, are, situation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>0</td>\n",
       "      <td>[of, course, dont, tease, me, you, know, i, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>[oh, ic, i, thought, you, meant, mary, jane]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "4663      0               [mum, not, going, robinson, already]\n",
       "3134      0  [wat, make, some, people, dearer, is, not, jus...\n",
       "61        0  [ha, ha, ha, good, joke, girl, are, situation,...\n",
       "5243      0  [of, course, dont, tease, me, you, know, i, si...\n",
       "1950      0       [oh, ic, i, thought, you, meant, mary, jane]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = processed_spam.copy()\n",
    "df = df.sample(frac=1)\n",
    "train_set = df.iloc[:4000]\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>0</td>\n",
       "      <td>[well, that, must, be, a, pain, to, catch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>0</td>\n",
       "      <td>[thk, shld, b, can, ya, i, wana, go, 4, lesson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>0</td>\n",
       "      <td>[sen, told, that, he, is, going, to, join, his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0</td>\n",
       "      <td>[so, wat, da, decision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>0</td>\n",
       "      <td>[not, enufcredeit, tocall, shall, ileave, uni,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "3222      0         [well, that, must, be, a, pain, to, catch]\n",
       "1392      0  [thk, shld, b, can, ya, i, wana, go, 4, lesson...\n",
       "4779      0  [sen, told, that, he, is, going, to, join, his...\n",
       "4500      0                            [so, wat, da, decision]\n",
       "5122      0  [not, enufcredeit, tocall, shall, ileave, uni,..."
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set = df.iloc[4000:]\n",
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  0 \t 0 \t | 0\n",
      "actual neg |  539 \t 3461 \t | 4000\n",
      "-------------------------------------\n",
      "Sums       |  539 \t 3461 \t | 4000\n",
      "   Accuracy  False Positive Rate  Precision Recall True Positive Rate\n",
      "0   0.86525              0.13475        0.0    N/A                N/A\n"
     ]
    }
   ],
   "source": [
    "#DEFAULT/BASE MODEL\n",
    "tmp = do_cv_class(train_set,10,'default') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  0 \t 0 \t | 0\n",
      "actual neg |  208 \t 1364 \t | 1572\n",
      "-------------------------------------\n",
      "Sums       |  208 \t 1364 \t | 1572\n",
      "   Accuracy  False Positive Rate  Precision Recall True Positive Rate\n",
      "0  0.867684             0.132316        0.0    N/A                N/A\n"
     ]
    }
   ],
   "source": [
    "#performance of Base model on validation set\n",
    "valid = get_pred_default(train_set,validation_set)\n",
    "print_cont_table(valid)\n",
    "print(get_metrics(valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  379 \t 8 \t | 387\n",
      "actual neg |  160 \t 3453 \t | 3613\n",
      "-------------------------------------\n",
      "Sums       |  539 \t 3461 \t | 4000\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0     0.958             0.044285   0.703154  0.979328            0.979328\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "tmp = do_cv_class(train_set,10,'logreg') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  168 \t 2 \t | 170\n",
      "actual neg |  40 \t 1362 \t | 1402\n",
      "-------------------------------------\n",
      "Sums       |  208 \t 1364 \t | 1572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.973282             0.028531   0.807692  0.988235            0.988235\n"
     ]
    }
   ],
   "source": [
    "#performance of Logreg model on validation set\n",
    "valid = get_pred_logreg(train_set,validation_set,rare_words)\n",
    "print_cont_table(valid)\n",
    "print(get_metrics(valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  465 \t 387 \t | 852\n",
      "actual neg |  74 \t 3074 \t | 3148\n",
      "-------------------------------------\n",
      "Sums       |  539 \t 3461 \t | 4000\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0   0.88475             0.023507   0.862709  0.545775            0.545775\n"
     ]
    }
   ],
   "source": [
    "#NAIVES BAYES\n",
    "tmp = do_cv_class(train_set,10,'nb') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  194 \t 147 \t | 341\n",
      "actual neg |  14 \t 1217 \t | 1231\n",
      "-------------------------------------\n",
      "Sums       |  208 \t 1364 \t | 1572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.897583             0.011373   0.932692  0.568915            0.568915\n"
     ]
    }
   ],
   "source": [
    "#performance of Naives Bayes on validation set\n",
    "valid = get_pred_nb(train_set,validation_set,rare_words)\n",
    "print_cont_table(valid)\n",
    "print(get_metrics(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  475 \t 9 \t | 484\n",
      "actual neg |  64 \t 3452 \t | 3516\n",
      "-------------------------------------\n",
      "Sums       |  539 \t 3461 \t | 4000\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0   0.98175             0.018203   0.881262  0.981405            0.981405\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "tmp = do_cv_class(train_set,10,'svm') # returns pandas dataframe\n",
    "print_cont_table(tmp.iloc[:, 0:2])\n",
    "print(get_metrics(tmp.iloc[:, 0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           |  PPos \t PNeg \t | Sums\n",
      "-------------------------------------\n",
      "actual pos |  192 \t 3 \t | 195\n",
      "actual neg |  16 \t 1361 \t | 1377\n",
      "-------------------------------------\n",
      "Sums       |  208 \t 1364 \t | 1572\n",
      "   Accuracy  False Positive Rate  Precision    Recall  True Positive Rate\n",
      "0  0.987913             0.011619   0.923077  0.984615            0.984615\n"
     ]
    }
   ],
   "source": [
    "#performance of Linear SVM on validation set\n",
    "valid = get_pred_svm(train_set,validation_set,rare_words)\n",
    "print_cont_table(valid)\n",
    "print(get_metrics(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM hence maintains the highest accuracy and lowest False Positive Rate on both k-fold cross validation and 2-step k-fold cross-validaiton approach. SVM hence is our chosen model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
